{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of AI & ML\n",
    "## Session 08\n",
    "### Experiment 3-Part-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters  \n",
    "\n",
    "A hyperparameter is a parameter whose value is set before the learning process begins.\n",
    "\n",
    "In this experiment we are going to tune the hyper parameters of MLPClassifier using MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the required packages**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST datset \n",
    "digits = datasets.load_digits(n_class=10)\n",
    "# Create our X and y data\n",
    "data = digits.data\n",
    "target = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1 ** Split the data into train,test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1078, 64) (359, 64) (360, 64)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_validation = np.split(data, [int(.6 * len(data)), int(.8 * len(data))])\n",
    "Y_train, Y_test, Y_validation = np.split(target, [int(.6 * len(target)), int(.8 * len(target))])\n",
    "print(X_train.shape, X_test.shape, X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to Create MLP classifier object with hyper parameters\n",
    "def mlp(a,s,h,lr):\n",
    "    clf = MLPClassifier(activation=a, solver=s, hidden_layer_sizes=h, max_iter=5000, learning_rate='constant', learning_rate_init=lr)\n",
    "    return clf \n",
    "\n",
    "#function to calculate the accuracy\n",
    "def accuracy(actual, predicted):\n",
    "    return np.count_nonzero(actual == predicted)*1.0/len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hyper parameters\n",
    "# activation\n",
    "a = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "#solvers\n",
    "s = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "#learning rate\n",
    "lr = [0.0001, 0.001, 0.01, 0.1]\n",
    "#hidden layers\n",
    "h = [(5, 2), (3, 2), (6, 3), (7, 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise 2 ** Calculate test and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyper-parameters = \n",
      " activation =  logistic \n",
      " solver =  adam \n",
      " learning_rate_init =  0.001 \n",
      " hidden_layer_sizes =  (6, 3)\n",
      "(train, val, test) accuracy =  0.974025974025974 0.7888888888888889 0.8217270194986073\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  relu \n",
      " solver =  lbfgs \n",
      " learning_rate_init =  0.1 \n",
      " hidden_layer_sizes =  (3, 2)\n",
      "(train, val, test) accuracy =  0.4313543599257885 0.375 0.362116991643454\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  logistic \n",
      " solver =  adam \n",
      " learning_rate_init =  0.001 \n",
      " hidden_layer_sizes =  (6, 3)\n",
      "(train, val, test) accuracy =  0.891465677179963 0.7083333333333334 0.7437325905292479\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  identity \n",
      " solver =  sgd \n",
      " learning_rate_init =  0.1 \n",
      " hidden_layer_sizes =  (3, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train, val, test) accuracy =  0.09925788497217068 0.09722222222222222 0.10027855153203342\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  tanh \n",
      " solver =  lbfgs \n",
      " learning_rate_init =  0.01 \n",
      " hidden_layer_sizes =  (7, 2)\n",
      "(train, val, test) accuracy =  0.6076066790352505 0.5277777777777778 0.520891364902507\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  logistic \n",
      " solver =  adam \n",
      " learning_rate_init =  0.01 \n",
      " hidden_layer_sizes =  (7, 2)\n",
      "(train, val, test) accuracy =  0.6799628942486086 0.5777777777777777 0.6183844011142061\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  relu \n",
      " solver =  lbfgs \n",
      " learning_rate_init =  0.1 \n",
      " hidden_layer_sizes =  (6, 3)\n",
      "(train, val, test) accuracy =  0.8237476808905381 0.6833333333333333 0.7019498607242339\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  identity \n",
      " solver =  lbfgs \n",
      " learning_rate_init =  0.1 \n",
      " hidden_layer_sizes =  (7, 2)\n",
      "(train, val, test) accuracy =  0.8293135435992579 0.6777777777777778 0.6880222841225627\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  relu \n",
      " solver =  sgd \n",
      " learning_rate_init =  0.1 \n",
      " hidden_layer_sizes =  (5, 2)\n",
      "(train, val, test) accuracy =  0.10296846011131726 0.10277777777777777 0.0947075208913649\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  tanh \n",
      " solver =  sgd \n",
      " learning_rate_init =  0.0001 \n",
      " hidden_layer_sizes =  (6, 3)\n",
      "(train, val, test) accuracy =  0.44712430426716143 0.34444444444444444 0.3871866295264624\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = []\n",
    "validation_accuracy = []\n",
    "train_accuracy = []\n",
    "for i in range(10):\n",
    "    k1 = np.random.randint(0, len(a))\n",
    "    k2 = np.random.randint(0, len(s))\n",
    "    k3 = np.random.randint(0, len(lr))\n",
    "    k4 = np.random.randint(0, len(h))\n",
    "    print(\"\\nHyper-parameters = \\n activation = \", a[k1],    \"\\n solver = \", s[k2], \"\\n learning_rate_init = \", lr[k3],         \"\\n hidden_layer_sizes = \", h[k4])\n",
    "    #calling the mlp function with random hyper paramters\n",
    "    clf = mlp(a[k1], s[k2], h[k4], lr[k3])\n",
    "    #Fitting the data into model\n",
    "    clf.fit(X_train, Y_train)\n",
    "    ## Predicting the values on trained model using train data\n",
    "    predTrain = clf.predict((X_train))\n",
    "    #Calculating the train accuracy\n",
    "    train_accuracy.append(accuracy(Y_train, predTrain))\n",
    "    # Predicting the values on trained model using test data\n",
    "    predTest = clf.predict((X_test))\n",
    "    #Calculating the test accuracy\n",
    "    test_accuracy.append(accuracy(Y_test, predTest))\n",
    "    ## Predicting the values on trained model using validation data\n",
    "    predVal = clf.predict((X_validation))\n",
    "    #Calculating the validation accuracy\n",
    "    validation_accuracy.append(accuracy(Y_validation,predVal))\n",
    "    print(\"(train, val, test) accuracy = \", accuracy(Y_train, predTrain), accuracy(Y_validation,predVal), accuracy(Y_test,predTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f497f8d3390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plotting the data\n",
    "xx = np.array(range(1,11))\n",
    "plt.bar(xx-0.2, train_accuracy, width=0.2)\n",
    "plt.bar(xx, validation_accuracy, width=0.2)\n",
    "plt.bar(xx+0.2, test_accuracy, width=0.2)\n",
    "plt.legend([\"Train\", \"Validation\", \"Test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solutions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_validation = np.split(data, [int(.6 * len(data)), int(.8 * len(data))])\n",
    "Y_train, Y_test, Y_validation = np.split(target, [int(.6 * len(target)), int(.8 * len(target))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy.append(accuracy(Y_test,predTest))\n",
    "validation_accuracy.append(accuracy(Y_validation,predVal))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
