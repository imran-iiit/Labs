{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of AI & ML\n",
    "## Session 09\n",
    "### Experiment 5 - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we will use RNN to classify text one character at a time.\n",
    "We will be using shakespeare.txt as our input file to the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind RNNs is to make use of sequential information. In a traditional neural network we assume that all inputs (and outputs) are independent of each other. But for many tasks thatâ€™s a very bad idea. If you want to predict the next word in a sentence you better know which words came before it. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being depended on the previous computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the unidecode package.\n",
    "\n",
    "To install the package run the following command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.0.22-py2.py3-none-any.whl (235kB)\n",
      "\u001b[K    100% |################################| 235kB 6.0MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.0.22\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing required packages\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115393\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "## code to find length of all_characters and storing the value in n_characters\n",
    "n_characters = len(all_characters)\n",
    "## code to convert unicode characters into plain ASCII.\n",
    "file = unidecode.unidecode(open('../Datasets/shakespeare.txt').read())\n",
    "## code to find length of the file\n",
    "file_len = len(file)\n",
    "## printing the length of the file\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(file[:1000])\n",
    "# all_characters[:100] # All printable characters!\n",
    "# string.printable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As the string is large, we are going to split it into chunks to provide inputs to the RNN using function random_chunk()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I had rather had eleven die nobly for their\n",
      "country than one voluptuously surfeit out of action.\n",
      "\n",
      "Gentlewoman:\n",
      "Madam, the Lady Valeria is come to visit you.\n",
      "\n",
      "VIRGILIA:\n",
      "Beseech you, give me leave to ret\n"
     ]
    }
   ],
   "source": [
    "## Initializing the length of chunk\n",
    "chunk_len = 200\n",
    "## Function to split the string into chunks\n",
    "def random_chunk():\n",
    "    ## Initializing the starting index value of the big string \n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    ## Initializing the ending index of the string \n",
    "    end_index = start_index + chunk_len + 1\n",
    "    ## returning the chunk\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will take as input the character for step $t_{-1}$ and is expected to output the next character $t$. There are three layers - one linear layer that encodes the input character into an internal state, one GRU layer (which may itself have multiple layers) that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution.\n",
    "\n",
    "Gated recurrent units (GRUs) are a gating mechanism in recurrent neural networks, introduced in 2014 by Kyunghyun Cho et al.[1] Their performance on polyphonic music modeling and speech signal modeling was found to be similar to that of long short-term memory. However, GRUs have been shown to exhibit better performance on smaller datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###importing required packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "### Creating recurrent neural network\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs and targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each chunk will be turned into a tensor, specifically a LongTensor (used for integer values), by looping through the characters of the string and looking up the index of each character in all_characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 10\n",
      " 11\n",
      " 12\n",
      " 39\n",
      " 40\n",
      " 41\n",
      "[torch.LongTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    ## tensor is a array\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters up to the last, and the target will be all characters from the first. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IAS: Whats going on here?\n",
    "\n",
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp() ### IAS: Whats this????????????????????\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep track of how long training takes, we have added a time_since(timestamp) function which returns a human readable string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing required packages\n",
    "import time, math\n",
    "## function to print amount of time passed\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output, target[c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the training parameters, instantiate the model, and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 7s (50 2%) 2.4894]\n",
      "Wh chand gne fot liald my\n",
      "\n",
      "UHYand iseef cord,\n",
      "Nin\n",
      "Sand sheapere gu, hear hu od wo lor yowim howe hen f \n",
      "\n",
      "[0m 15s (100 5%) 2.2483]\n",
      "Whath and and by of lomessce moweze von nantt I the Ror harl thom owe mofrd houd gis the Ie fou bly th \n",
      "\n",
      "[0m 23s (150 7%) 2.1724]\n",
      "Whe onom and no lovere hien, comer not I lou soull so o dor the fou do fay fo ray prading I your, of i \n",
      "\n",
      "[0m 30s (200 10%) 2.1454]\n",
      "Whis my ele.\n",
      "\n",
      "RUCARD\n",
      "EBe's I is and in will dous to the my shinces no the her or.\n",
      "\n",
      "RING RIIHAM:\n",
      "\n",
      "NTARD \n",
      "\n",
      "[0m 38s (250 12%) 2.1599]\n",
      "When, make hatt will, for gater,\n",
      "I me ant be han thy be thee orle, freen and your be'd the par to ; un \n",
      "\n",
      "[0m 46s (300 15%) 2.0421]\n",
      "Whath mes?\n",
      "\n",
      "KING RIIY thing may merust me sean respalind sous manes in the he fort,\n",
      "Thath fore me brak \n",
      "\n",
      "[0m 54s (350 17%) 2.1160]\n",
      "Whly live a I rerinen a the lie,\n",
      "I waemand ner the wolld sive is slot one he proby to ost home her my  \n",
      "\n",
      "[1m 1s (400 20%) 1.8147]\n",
      "Whser fay or me fare for,\n",
      "And nou sefte to faindelf rotail, sils fore?\n",
      "O man, lien:\n",
      "To so we dendest t \n",
      "\n",
      "[1m 9s (450 22%) 2.1550]\n",
      "Whe wome that stis sis amfu\n",
      "And ther, execes your feare word shat now, thifing the whingher: the not w \n",
      "\n",
      "[1m 17s (500 25%) 1.9212]\n",
      "What uming the four thy, whinem\n",
      "Whing might't in inery, cark betleming his in cound reaty whering mere \n",
      "\n",
      "[1m 25s (550 27%) 2.0006]\n",
      "What his be fages forgh the lews gitere.\n",
      "\n",
      "HRENRY RICIA:\n",
      "If go me thinnes the pares thew asing fanous t \n",
      "\n",
      "[1m 32s (600 30%) 1.9960]\n",
      "Wher im that seemast enterge;\n",
      "Thy de lows.\n",
      "This say agal be are this seets;\n",
      "And man that thy my grace  \n",
      "\n",
      "[1m 40s (650 32%) 2.0680]\n",
      "Wh!\n",
      "To dids your me\n",
      "Lale it for more, tarit more, thy son.\n",
      "\n",
      "PETRUTUS:\n",
      "Sope cast it.\n",
      "\n",
      "RICHAfL ather.\n",
      "\n",
      "R \n",
      "\n",
      "[1m 48s (700 35%) 1.8337]\n",
      "Whicem, that for of thear\n",
      "And to mothering thelear and the could you the reath,\n",
      "No with thast the comm \n",
      "\n",
      "[1m 55s (750 37%) 1.9569]\n",
      "Wham it fot.\n",
      "\n",
      "BOBANTIO:\n",
      "An is thou and fore thou spur comes,--natt in for here shall And sold me ford  \n",
      "\n",
      "[2m 3s (800 40%) 1.9761]\n",
      "Whard thate is my;\n",
      "Here not I ponest the reconshorsere do theire dold saine, bend thy my bent are exen \n",
      "\n",
      "[2m 11s (850 42%) 2.0698]\n",
      "Which roon,\n",
      "And who evers sughiess to her for my cude't in full frice.\n",
      "\n",
      "he the the queais, and her he  \n",
      "\n",
      "[2m 18s (900 45%) 2.0310]\n",
      "Wher the chance Parded.\n",
      "So kind whenpure.\n",
      "\n",
      "MAULIO:\n",
      "And thou and I with my and is in knent my whefe him \n",
      "\n",
      "[2m 26s (950 47%) 1.9344]\n",
      "Whiou reads here to with my wake give make evere the\n",
      "EN my a sap and my love with mine of to so not in \n",
      "\n",
      "[2m 34s (1000 50%) 1.9840]\n",
      "Whone attor shall som more\n",
      "Is fat herse rese! O like or whill which uppes.\n",
      "\n",
      "HRANGENTIO:\n",
      "What the not t \n",
      "\n",
      "[2m 41s (1050 52%) 1.6786]\n",
      "Whith his all how my so manathal speair he liding\n",
      "And mus more mess good, I themand beards.\n",
      "\n",
      "WASTALA:\n",
      " \n",
      "\n",
      "[2m 49s (1100 55%) 1.7874]\n",
      "What, wolds enter the melue,\n",
      "For sir you, and, has know dear, fir, furse cord,\n",
      "Thill well been me to d \n",
      "\n",
      "[2m 57s (1150 57%) 1.8255]\n",
      "What will wit rapece,\n",
      "Ay, clan with my workince this wih quie, for loves house! thing on nothered be s \n",
      "\n",
      "[3m 5s (1200 60%) 2.1026]\n",
      "Whto beder lirers\n",
      "Unten dind there where that wes the depades sop my well.\n",
      "\n",
      "POLIXENES:\n",
      "Tell this of th \n",
      "\n",
      "[3m 12s (1250 62%) 1.7522]\n",
      "Where offore his if be defoother dow?\n",
      "\n",
      "PILIUS:\n",
      "Whot for with couter's for for head know he more thine! \n",
      "\n",
      "[3m 20s (1300 65%) 1.5933]\n",
      "What you, sunsles smay,\n",
      "Which nast with forsing it he give any it reford,\n",
      "When parest bet with bewary, \n",
      "\n",
      "[3m 28s (1350 67%) 1.8906]\n",
      "Wher as troffuly, the distred the mind to be\n",
      "ho the dead in these to case:\n",
      "I'll a comies nore that for \n",
      "\n",
      "[3m 35s (1400 70%) 1.8374]\n",
      "What hee sent wind in toul for good more gidser to 's des.\n",
      "\n",
      "COGUTES:\n",
      "I lap, with my sempake,\n",
      "on him th \n",
      "\n",
      "[3m 43s (1450 72%) 1.7320]\n",
      "Whrese you chith my for bucks,\n",
      "And with uster sight itor, lord, but old. Weys all, let stay, me the wi \n",
      "\n",
      "[3m 51s (1500 75%) 1.9111]\n",
      "Whttence menent,\n",
      "If eny to the many fath, tere he his me galts a retedry\n",
      "Lut, the sunce flemar? I tthe \n",
      "\n",
      "[3m 59s (1550 77%) 1.8859]\n",
      "Whall I be-ore come.\n",
      "Gresen shats it shall here shall hour blatters, so to Seever there\n",
      "wou, of least  \n",
      "\n",
      "[4m 6s (1600 80%) 1.7928]\n",
      "Wher or demy,\n",
      "Now, and sam his the lown blest this our let in soul, where.\n",
      "\n",
      "GRIEL:\n",
      "And my some to or o \n",
      "\n",
      "[4m 14s (1650 82%) 1.8460]\n",
      "Where his bewl:\n",
      "O, and a goand out of sort.\n",
      "\n",
      "Claizen the, tardine you Roocks to though,\n",
      "How look my sh \n",
      "\n",
      "[4m 22s (1700 85%) 2.0160]\n",
      "Whttelu shast, you mong:\n",
      "My hose a great your genguell all and is his there:\n",
      "I precare his secpament a \n",
      "\n",
      "[4m 29s (1750 87%) 1.4802]\n",
      "What, love and the fear with you and here in man her say\n",
      "A love offeremn him, and a cuild:\n",
      "The wolk su \n",
      "\n",
      "[4m 37s (1800 90%) 1.7375]\n",
      "Wher, surner befor concome:\n",
      "\n",
      "CORIOLANUS:\n",
      "The meanucit of peadounged chander in one.\n",
      "\n",
      "CLAUDIO:\n",
      "Ay for t \n",
      "\n",
      "[4m 45s (1850 92%) 1.4078]\n",
      "Why, me?\n",
      "\n",
      "LADY CETRIUS:\n",
      "Why, that I house.\n",
      "\n",
      "QUEEN MARGSENIO:\n",
      "Thy queen to him frains.\n",
      "\n",
      "NORKINCIILAS:\n",
      "N \n",
      "\n",
      "[4m 52s (1900 95%) 1.7074]\n",
      "Wht is bury.\n",
      "Well he praty plate will none,\n",
      "And to me are go the rovos;\n",
      "And gond in Heder bus on the l \n",
      "\n",
      "[5m 0s (1950 97%) 1.6429]\n",
      "What sigeen your nours!\n",
      "Lie, your cleat my my night not king.\n",
      "As my his count that I lord; ast my we a \n",
      "\n",
      "[5m 8s (2000 100%) 1.9561]\n",
      "Wht see at death grove doth from they traming.\n",
      "\n",
      "QUEEN EYRY VI:\n",
      "I am yourse, sir, and say, set sen she  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000 #Number of epochs\n",
    "print_every = 50\n",
    "plot_every = 20\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "## Optimizer\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "## Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "#In this for loop for every 100th iteration we are printing the time taken, loss and the chunk.\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate('Wh', 100), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_training_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the Training Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the historical loss from all_losses shows the network learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd3b7590278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapting or tuning for prose writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the evaluate function above, every time a prediction is made the outputs are divided by the \"temperature\" argument passed. Using a higher number makes all actions more equally likely, and thus gives us \"more random\" outputs. Using a lower value (less than 1) makes high probabilities contribute more. As we turn the temperature towards zero we are choosing only the most likely outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the effects of this by adjusting the temperature argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utus be speak signe\n",
      "And let thy lost to you, boy be the's fied\n",
      "Hall heard the made a pring of the with prood of to this appity\n",
      "To be gadon's of there sever's the shall seaves save tade of I shall fortu\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('u', 200, temperature=0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower temperatures are less varied, choosing only the more probable outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That the shall the shall the son the she should see the shall the should\n",
      "And the so the shall the shall the shall the she the shall the sone the she she shall the the shall the shall the son.\n",
      "\n",
      "GLOUCESTE\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 200, temperature=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Higher temperatures more varied, choosing less probable outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how!\n",
      "Oraflevef, vist tenions, sebie.; your about tigser:\n",
      "My lorms am Kowby fefcom, likes udoss ForweNef-tilein ifrne,\n",
      "A ttime tall-burdiengcer, eno'll besiriol\n",
      "AgL downos, 'I givetmys cam! olds alab my b\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('how', 200, temperature=1.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1:\n",
    "\n",
    "Change the number of epochs to 1000. Calculate the time taken and loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2:\n",
    "\n",
    "Change the print every to 50 and plot every to 20. Calculate the time taken and loss and plot the loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
